{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her er jeres første rigtige opgave! I skal lave bruge [yfinance](https://mercantec.notion.site/yfinance-8f05decbf9a040659da38616e432ed62?pvs=4) også kaldet Yahoo Finance, til at trække data ned på jeres yndlingsaktie! I skal herfra lave en regressionsmodel på dataet. Det involvere at splitte dataet op i træningsdata og testdata. \n",
    "Nedenunder er der lige et code-snippet til at få jer startet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi skal bruge følgende pakker til at starte vores projekt, en del af dem kender I. Pandas fra første dag, datetime har i nok arbejdet med lignende pakker før. [yfinance](https://mercantec.notion.site/yfinance-8f05decbf9a040659da38616e432ed62?pvs=4) er den som er linket til ovenfor og har alt det data vi skal bruge. Til sidste er der matplitlib, den er ikke strengt nødvendig for vores projekt, men det hjælper ofte at få et visuelt billede på! Dokumentation kan findes [her](https://mercantec.notion.site/MatPlotLib-bb10bec44c8e4bc28ac511017dbc895d?pvs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance as yf\n",
    "# import pandas as pd\n",
    "# from datetime import date, timedelta\n",
    "# from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi bruger datetime pakken til at sætte et startspunkt og et slutpunkt. Startspunktet er for 365 dage siden og slutpunktet er for 2 dage siden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start = date.today() - timedelta(365)\n",
    "# Start.strftime('%Y-%m-%d')\n",
    "\n",
    "# End = date.today() - timedelta(2)\n",
    "# End.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi laver en funktion som tager en \"ticker\" ind, altså en aktie. \n",
    "Her bruger vi så Pandas, pd, til at en dataframe som indeholder vores data omkring den valgte ticker, med slut og startsdato som definere før."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def closing_price(ticker):\n",
    "#     Asset = pd.DataFrame(yf.download(ticker, start=Start,\n",
    "#       end=End))\n",
    "#     return Asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu kan vi bruge vores funktion til at se på vores data. Her bruger vi Microsoft aktien, MSFT. Standarten er at vi for dato, åbningsprisen, højeste og laveste på dagen, lukke prisen og den justerede lukkepris. Vi kan så bruge matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# microsoft = closing_price('MSFT')\n",
    "# print(microsoft)\n",
    "# plt.plot(microsoft['Adj Close'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opgaven\n",
    "\n",
    "Opgaven går nu på at I skal bruge jeres viden omkring regression på at lave en model som kan forudsige hvad aktie prisen bliver over den næste periode eller forhåbenligt bare en retning. \n",
    "\n",
    "Det er ikke målet at I skal finde en model som gør det, men at I skal lege rundt med det. De værktøjer som vi har fået indtil videre, er ikke nok til at kunne lave en model som har noget grundlag. Det data vi for er heller ikke nok. \n",
    "\n",
    "I kan tage inspiration ud fra dokumenterne her [regression](https://github.com/MAGS-Template/MachineLearning/blob/main/1.%20Regression/1.%20regression.ipynb) og [regression med data](https://github.com/MAGS-Template/MachineLearning/blob/main/1.%20Regression/2.%20regression_with_data.ipynb) - det er filerne i samme mappe som den her!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "Start = date.today() - timedelta(1095)\n",
    "Start.strftime('%Y-%m-%d')\n",
    "End = date.today() - timedelta(2)\n",
    "End.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def logger(data, extra = \"\\n\"):\n",
    "    if (True):\n",
    "        print(data, extra)\n",
    "\n",
    "def closing_price(ticker):\n",
    "    Asset = pd.DataFrame(yf.download(ticker, start=Start,\n",
    "      end=End))\n",
    "    return Asset\n",
    "\n",
    "def build_and_compile_model(input_shape):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(units=64,\n",
    "                                return_sequences=True,\n",
    "                                input_shape=input_shape))\n",
    "    model.add(keras.layers.LSTM(units=64))\n",
    "    model.add(keras.layers.Dense(32))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# getting the dataset and cleaning\n",
    "# stockData = closing_price('MSFT')\n",
    "# stockData = closing_price('AAPL')\n",
    "# stockData = closing_price('TSLA')\n",
    "stockData = closing_price('GOOG')\n",
    "stockData.drop(columns=['Adj Close'], inplace=True)\n",
    "dataset = stockData.copy()\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "scaled_data = pd.DataFrame(scaled_data, index=dataset.index, columns=dataset.columns)\n",
    "logger(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into a training set and a test set.\n",
    "# train_dataset = scaled_data.sample(frac=0.8, random_state=0)\n",
    "# test_dataset = scaled_data.drop(train_dataset.index)\n",
    "train_dataset, test_dataset = np.split(scaled_data, [int(.8*len(scaled_data))])\n",
    "\n",
    "print(train_dataset.head())\n",
    "print(test_dataset.head())\n",
    "\n",
    "\n",
    "print(\"training dataset count:\")\n",
    "print(train_dataset.count(), '\\n')\n",
    "print(\"test dataset count:\")\n",
    "print(test_dataset.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and labels\n",
    "train_features = train_dataset.copy().astype('float32')\n",
    "test_features = test_dataset.copy().astype('float32')\n",
    "\n",
    "train_labels = train_features.pop('Close')\n",
    "test_labels = test_features.pop('Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger(train_features.shape[1])\n",
    "dnn_model = build_and_compile_model((train_features.shape[1],1))\n",
    "logger(dnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = dnn_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=.02,\n",
    "    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)\n",
    "logger(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnn_model = tf.keras.models.load_model(\"models/MSFT\")\n",
    "#dnn_model.save('models/MSFT')\n",
    "test_predictions = dnn_model.predict(test_features).flatten()\n",
    "\n",
    "\n",
    "logger(len(test_features))\n",
    "logger(len(test_labels))\n",
    "logger(test_labels.head())\n",
    "test_predictions = pd.Series(test_predictions, index=test_labels.index)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(train_labels, color=\"b\")\n",
    "plt.plot(test_predictions, color=\"r\")\n",
    "plt.plot(test_labels, color=\"g\")\n",
    "plt.show()\n",
    "logger(test_labels.compare(test_predictions).tail())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
